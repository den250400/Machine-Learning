{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from math import *\n",
    "\n",
    "def model_inputs(real_dim, z_dim):\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, real_dim, real_dim, 1), name=\"inputs_real\")\n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim))\n",
    "    return inputs_real, inputs_z\n",
    "\n",
    "def generator(z, input_size=64, reuse=False,  alpha=0.01):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # Hidden layer 1\n",
    "        h1 = tf.layers.dense(z, (input_size//8)*(input_size//8)*256, activation=None)\n",
    "        h1 = tf.reshape(h1, [-1, (input_size//8), (input_size//8), 256])\n",
    "        h1 = tf.maximum(h1, alpha*h1)\n",
    "        h1 = tf.nn.dropout(h1, 0.4)\n",
    "        # Upsampling-convolution layer 1\n",
    "        upsample1 = tf.image.resize_nearest_neighbor(h1, [(input_size//4), (input_size//4)])\n",
    "        conv1_1 = tf.layers.conv2d(inputs=upsample1, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_1\")\n",
    "        conv1_1 = tf.maximum(conv1_1, alpha*conv1_1)\n",
    "        norm1_1 = tf.contrib.layers.batch_norm(inputs = conv1_1)\n",
    "        conv1_2 = tf.layers.conv2d(inputs=norm1_1, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_2\")\n",
    "        conv1_2 = tf.maximum(conv1_2, alpha*conv1_2)\n",
    "        norm1_2 = tf.contrib.layers.batch_norm(inputs = conv1_2)\n",
    "        conv1_3 = tf.layers.conv2d(inputs=norm1_2, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_3\")\n",
    "        conv1_3 = tf.maximum(conv1_3, alpha*conv1_3)\n",
    "        norm1_3 = tf.contrib.layers.batch_norm(inputs = conv1_3)\n",
    "        conv1_4 = tf.layers.conv2d(inputs=norm1_3, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_4\")\n",
    "        conv1_4 = tf.maximum(conv1_4, alpha*conv1_4)\n",
    "        norm1_4 = tf.contrib.layers.batch_norm(inputs = conv1_4)\n",
    "        \n",
    "        # Upsampling-convolution layer 2\n",
    "        upsample2 = tf.image.resize_nearest_neighbor(norm1_4, [input_size//2, input_size//2])\n",
    "        conv2_1 = tf.layers.conv2d(inputs=upsample2, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_1\")\n",
    "        conv2_1 = tf.maximum(conv2_1, alpha*conv2_1)\n",
    "        norm2_1 = tf.contrib.layers.batch_norm(inputs = conv2_1)\n",
    "        conv2_2 = tf.layers.conv2d(inputs=norm2_1, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_2\")\n",
    "        conv2_2 = tf.maximum(conv2_2, alpha*conv2_2)\n",
    "        norm2_2 = tf.contrib.layers.batch_norm(inputs = conv2_2)\n",
    "        conv2_3 = tf.layers.conv2d(inputs=norm2_2, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_3\")\n",
    "        conv2_3 = tf.maximum(conv2_3, alpha*conv2_3)\n",
    "        norm2_3 = tf.contrib.layers.batch_norm(inputs = conv2_3)\n",
    "        conv2_4 = tf.layers.conv2d(inputs=norm2_3, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_4\")\n",
    "        conv2_4 = tf.maximum(conv2_4, alpha*conv2_4)\n",
    "        norm2_4 = tf.contrib.layers.batch_norm(inputs = conv2_4)\n",
    "        \n",
    "        # Upsampling-convolution layer 3\n",
    "        upsample3 = tf.image.resize_nearest_neighbor(norm2_4, [input_size, input_size])\n",
    "        conv3_1 = tf.layers.conv2d(inputs=upsample3, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_1\")\n",
    "        conv3_1 = tf.maximum(conv3_1, alpha*conv3_1)\n",
    "        norm3_1 = tf.contrib.layers.batch_norm(inputs = conv3_1)\n",
    "        conv3_2 = tf.layers.conv2d(inputs=norm3_1, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_2\")\n",
    "        conv3_2 = tf.maximum(conv3_2, alpha*conv3_2)\n",
    "        norm3_2 = tf.contrib.layers.batch_norm(inputs = conv3_2)\n",
    "        conv3_3 = tf.layers.conv2d(inputs=norm3_2, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_3\")\n",
    "        conv3_3 = tf.maximum(conv3_3, alpha*conv3_3)\n",
    "        norm3_3 = tf.contrib.layers.batch_norm(inputs = conv3_3)\n",
    "        conv3_4 = tf.layers.conv2d(inputs=norm3_3, filters=1, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_4\")\n",
    "        \n",
    "        # Logits and tanh output\n",
    "        logits = conv3_4\n",
    "        out = tf.nn.tanh(logits)\n",
    "        tf.summary.image(\"Generated_image\", (tf.reshape(out, [-1, input_size, input_size, 1])+1) * 0.5, 3)\n",
    "        \n",
    "        return out, logits\n",
    "        \n",
    "        \n",
    "# Size of input image to discriminator\n",
    "input_size = 64 # 64x64 Face images\n",
    "# Size of latent vector to generator\n",
    "z_size = 100\n",
    "# Leak factor for leaky ReLU\n",
    "alpha = 0.01\n",
    "# Label smoothing \n",
    "smooth = 0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Create our input placeholders\n",
    "input_real, input_z = model_inputs(input_size, z_size)\n",
    "\n",
    "# Generator network here\n",
    "g_model, g_logits = generator(input_z, input_size,reuse=False,  alpha=alpha)\n",
    "# g_model is the generator output\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
    "\n",
    "logging_step = 50\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "samples = []\n",
    "losses = []\n",
    "saver = tf.train.Saver(var_list = g_vars)\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'Weights/ganFaces1')\n",
    "    N_images = int(input('Enter the number of images to generate: '))\n",
    "    plt.figure(figsize=(10, ((N_images // 5)+1)))\n",
    "    for n in range(N_images):\n",
    "        batch_z = np.random.uniform(-1, 1, size=(1, z_size))\n",
    "        plt.subplot(((N_images // 5) + 1), 5, n+1)\n",
    "        generated_pic = g_model.eval(feed_dict={input_z: batch_z}).reshape((input_size, input_size))\n",
    "        plt.imshow(generated_pic, cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
