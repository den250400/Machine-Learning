{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from math import *\n",
    "\n",
    "def model_inputs(real_dim, z_dim):\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, real_dim, real_dim, 1), name=\"inputs_real\")\n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim))\n",
    "    return inputs_real, inputs_z\n",
    "\n",
    "def generator(z, input_size=64, reuse=False,  alpha=0.01):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # Hidden layer 1\n",
    "        h1 = tf.layers.dense(z, (input_size//8)*(input_size//8)*256, activation=None)\n",
    "        h1 = tf.reshape(h1, [-1, (input_size//8), (input_size//8), 256])\n",
    "        h1 = tf.maximum(h1, alpha*h1)\n",
    "        h1 = tf.nn.dropout(h1, 0.4)\n",
    "        # Upsampling-convolution layer 1\n",
    "        upsample1 = tf.image.resize_nearest_neighbor(h1, [(input_size//4), (input_size//4)])\n",
    "        conv1_1 = tf.layers.conv2d(inputs=upsample1, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_1\")\n",
    "        conv1_1 = tf.maximum(conv1_1, alpha*conv1_1)\n",
    "        norm1_1 = tf.contrib.layers.batch_norm(inputs = conv1_1)\n",
    "        conv1_2 = tf.layers.conv2d(inputs=norm1_1, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_2\")\n",
    "        conv1_2 = tf.maximum(conv1_2, alpha*conv1_2)\n",
    "        norm1_2 = tf.contrib.layers.batch_norm(inputs = conv1_2)\n",
    "        conv1_3 = tf.layers.conv2d(inputs=norm1_2, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_3\")\n",
    "        conv1_3 = tf.maximum(conv1_3, alpha*conv1_3)\n",
    "        norm1_3 = tf.contrib.layers.batch_norm(inputs = conv1_3)\n",
    "        conv1_4 = tf.layers.conv2d(inputs=norm1_3, filters=256, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_4\")\n",
    "        conv1_4 = tf.maximum(conv1_4, alpha*conv1_4)\n",
    "        norm1_4 = tf.contrib.layers.batch_norm(inputs = conv1_4)\n",
    "        \n",
    "        # Upsampling-convolution layer 2\n",
    "        upsample2 = tf.image.resize_nearest_neighbor(norm1_4, [input_size//2, input_size//2])\n",
    "        conv2_1 = tf.layers.conv2d(inputs=upsample2, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_1\")\n",
    "        conv2_1 = tf.maximum(conv2_1, alpha*conv2_1)\n",
    "        norm2_1 = tf.contrib.layers.batch_norm(inputs = conv2_1)\n",
    "        conv2_2 = tf.layers.conv2d(inputs=norm2_1, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_2\")\n",
    "        conv2_2 = tf.maximum(conv2_2, alpha*conv2_2)\n",
    "        norm2_2 = tf.contrib.layers.batch_norm(inputs = conv2_2)\n",
    "        conv2_3 = tf.layers.conv2d(inputs=norm2_2, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_3\")\n",
    "        conv2_3 = tf.maximum(conv2_3, alpha*conv2_3)\n",
    "        norm2_3 = tf.contrib.layers.batch_norm(inputs = conv2_3)\n",
    "        conv2_4 = tf.layers.conv2d(inputs=norm2_3, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_4\")\n",
    "        conv2_4 = tf.maximum(conv2_4, alpha*conv2_4)\n",
    "        norm2_4 = tf.contrib.layers.batch_norm(inputs = conv2_4)\n",
    "        \n",
    "        # Upsampling-convolution layer 3\n",
    "        upsample3 = tf.image.resize_nearest_neighbor(norm2_4, [input_size, input_size])\n",
    "        conv3_1 = tf.layers.conv2d(inputs=upsample3, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_1\")\n",
    "        conv3_1 = tf.maximum(conv3_1, alpha*conv3_1)\n",
    "        norm3_1 = tf.contrib.layers.batch_norm(inputs = conv3_1)\n",
    "        conv3_2 = tf.layers.conv2d(inputs=norm3_1, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_2\")\n",
    "        conv3_2 = tf.maximum(conv3_2, alpha*conv3_2)\n",
    "        norm3_2 = tf.contrib.layers.batch_norm(inputs = conv3_2)\n",
    "        conv3_3 = tf.layers.conv2d(inputs=norm3_2, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_3\")\n",
    "        conv3_3 = tf.maximum(conv3_3, alpha*conv3_3)\n",
    "        norm3_3 = tf.contrib.layers.batch_norm(inputs = conv3_3)\n",
    "        conv3_4 = tf.layers.conv2d(inputs=norm3_3, filters=1, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_4\")\n",
    "        \n",
    "        # Logits and tanh output\n",
    "        logits = conv3_4\n",
    "        out = tf.nn.tanh(logits)\n",
    "        tf.summary.image(\"Generated_image\", (tf.reshape(out, [-1, input_size, input_size, 1])+1) * 0.5, 3)\n",
    "        \n",
    "        return out, logits\n",
    "        \n",
    "def discriminator(x, input_size=28, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # Convolutional layer 1\n",
    "        conv1_1 = tf.layers.conv2d(inputs=x, filters=32, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_1\")\n",
    "        conv1_1 = tf.maximum(conv1_1, alpha*conv1_1)\n",
    "        norm1_1 = tf.contrib.layers.batch_norm(inputs = conv1_1)\n",
    "        conv1_2 = tf.layers.conv2d(inputs=norm1_1, filters=32, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv1_2\")\n",
    "        conv1_2 = tf.maximum(conv1_2, alpha*conv1_2)\n",
    "        norm1_2 = tf.contrib.layers.batch_norm(inputs = conv1_2)\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=norm1_2, pool_size=[2, 2], strides=2, name = \"pool1\")\n",
    "        # Convolutional layer 2\n",
    "        conv2_1 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_1\")\n",
    "        conv2_1 = tf.maximum(conv2_1, alpha*conv2_1)\n",
    "        norm2_1 = tf.contrib.layers.batch_norm(inputs = conv2_1)\n",
    "        conv2_2 = tf.layers.conv2d(inputs=norm2_1, filters=64, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv2_2\")\n",
    "        conv2_2 = tf.maximum(conv2_2, alpha*conv2_2)\n",
    "        norm2_2 = tf.contrib.layers.batch_norm(inputs = conv2_2)\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=norm2_2, pool_size=[2, 2], strides=2, name = \"pool2\")\n",
    "        # Convolutional layer 2\n",
    "        conv3_1 = tf.layers.conv2d(inputs=pool2, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_1\")\n",
    "        conv3_1 = tf.maximum(conv3_1, alpha*conv3_1)\n",
    "        norm3_1 = tf.contrib.layers.batch_norm(inputs = conv3_1)\n",
    "        conv3_2 = tf.layers.conv2d(inputs=norm3_1, filters=128, kernel_size=[5, 5], padding=\"same\", activation=None, name = \"conv3_2\")\n",
    "        conv3_2 = tf.maximum(conv3_2, alpha*conv3_2)\n",
    "        norm3_2 = tf.contrib.layers.batch_norm(inputs = conv3_2)\n",
    "        pool3 = tf.layers.max_pooling2d(inputs=norm3_2, pool_size=[2, 2], strides=2, name = \"pool3\")\n",
    "        flatten = tf.reshape(pool3, [-1, 128*(input_size//8)*(input_size//8)])\n",
    "        flatten = tf.nn.dropout(flatten, 0.4)\n",
    "        logits = tf.layers.dense(flatten, 1, activation=None)\n",
    "        out = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return out, logits\n",
    "        \n",
    "# Size of input image to discriminator\n",
    "input_size = 64 #Side of the image\n",
    "# Size of latent vector to generator\n",
    "z_size = 100\n",
    "# Leak factor for leaky ReLU\n",
    "alpha = 0.01\n",
    "# Label smoothing \n",
    "smooth = 0.1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Create our input placeholders\n",
    "input_real, input_z = model_inputs(input_size, z_size)\n",
    "tf.summary.image(\"Real_image_sample\", (tf.reshape(input_real, [-1, input_size, input_size, 1])+1) * 0.5, 3)\n",
    "# Generator network here\n",
    "g_model, g_logits = generator(input_z, input_size, reuse=False,  alpha=alpha)\n",
    "# g_model is the generator output\n",
    "\n",
    "# Disriminator network here\n",
    "d_model_real, d_logits_real = discriminator(input_real, input_size, reuse=False, alpha=alpha)\n",
    "d_model_fake, d_logits_fake = discriminator(g_model, input_size, reuse=True, alpha=alpha)\n",
    "\n",
    "# Calculate losses\n",
    "d_labels_real = tf.ones_like(d_logits_real) * (1 - smooth)\n",
    "d_labels_fake = tf.zeros_like(d_logits_fake)\n",
    "\n",
    "d_loss_real = tf.nn.sigmoid_cross_entropy_with_logits(labels=d_labels_real, logits=d_logits_real)\n",
    "d_loss_fake = tf.nn.sigmoid_cross_entropy_with_logits(labels=d_labels_fake, logits=d_logits_fake)\n",
    "\n",
    "d_loss = tf.reduce_mean(d_loss_real + d_loss_fake)\n",
    "tf.summary.scalar(\"Disc_loss\", d_loss)\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=tf.ones_like(d_logits_fake), \n",
    "        logits=d_logits_fake))\n",
    "tf.summary.scalar(\"Gen_loss\", g_loss)\n",
    "tf.summary.scalar(\"Mean_difference_disc\", tf.reduce_mean(tf.ones_like(d_logits_fake)-d_model_fake))\n",
    "# Optimizers\n",
    "disc_lr = 0.001\n",
    "gen_lr = 0.0001\n",
    "\n",
    "# Get the trainable_variables, split into G and D parts\n",
    "t_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in t_vars if var.name.startswith(\"generator\")]\n",
    "d_vars = [var for var in t_vars if var.name.startswith(\"discriminator\")]\n",
    "\n",
    "d_train_opt = tf.train.AdamOptimizer(learning_rate=disc_lr).minimize(d_loss, var_list=d_vars)\n",
    "g_train_opt = tf.train.AdamOptimizer(learning_rate=gen_lr).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "logging_step = 50\n",
    "data = np.load('Datasets/olivetti_faces.npy')\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'Weights/ganFaces1')\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    summary_counter = 0\n",
    "    writer = tf.summary.FileWriter(\"./Logs\")\n",
    "    writer.add_graph(sess.graph)\n",
    "    for e in range(epochs):\n",
    "        np.random.shuffle(data)\n",
    "        for ii in range(data.shape[0]//batch_size):\n",
    "            batch = data[ii*batch_size:(ii+1)*batch_size]\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch.reshape((batch_size, input_size, input_size, 1))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Sample random noise for G\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "            \n",
    "            # Run optimizers\n",
    "            sess.run(d_train_opt, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "            sess.run(g_train_opt, feed_dict={input_z: batch_z})\n",
    "            #Logging\n",
    "            if ii % logging_step == 0:\n",
    "                s = sess.run(merged_summary, feed_dict={input_real: batch_images, input_z: batch_z})\n",
    "                writer.add_summary(s, summary_counter*logging_step)\n",
    "                summary_counter += 1\n",
    "        \n",
    "        # At the end of each epoch, get the losses and print them out\n",
    "        train_loss_d = sess.run(d_loss, {input_z: batch_z, input_real: batch_images})\n",
    "        train_loss_g = g_loss.eval({input_z: batch_z})\n",
    "            \n",
    "        print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "              \"Generator Loss: {:.4f}\".format(train_loss_g))    \n",
    "        saver.save(sess, 'Weights/ganFaces1_2')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
